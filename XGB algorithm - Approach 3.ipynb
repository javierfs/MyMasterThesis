{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'--Data splitted done'\n"
     ]
    }
   ],
   "source": [
    "#importing all the required ML packages\n",
    "from sklearn.linear_model import LogisticRegression #logistic regression\n",
    "from sklearn import svm #support vector Machine\n",
    "from sklearn.ensemble import RandomForestClassifier #Random Forest\n",
    "from sklearn.neighbors import KNeighborsClassifier #KNN\n",
    "from sklearn.naive_bayes import GaussianNB #Naive bayes\n",
    "from sklearn.tree import DecisionTreeClassifier #Decision Tree\n",
    "from sklearn.model_selection import train_test_split #training and testing data split\n",
    "from sklearn import metrics #accuracy measure\n",
    "from sklearn.metrics import confusion_matrix #for confusion matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from pprint import pprint\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression #logistic regression\n",
    "from sklearn import svm #support vector Machine\n",
    "from sklearn.ensemble import RandomForestClassifier #Random Forest\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split #training and testing data split\n",
    "from sklearn import metrics #accuracy measure\n",
    "from sklearn.metrics import confusion_matrix #for confusion matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from time import time\n",
    "from operator import itemgetter\n",
    "from scipy.stats import randint\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn.cross_validation import  cross_val_score\n",
    "import os\n",
    "import subprocess\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from time import time\n",
    "from operator import itemgetter\n",
    "from scipy.stats import randint\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "filename = 'df_imputed_scaled_OHE_reduced.pkl'\n",
    "df = pd.read_pickle(filename)\n",
    "X = df[df.columns[:-1]]\n",
    "y = pd.Series(df['heartdisease'])\n",
    "#train_X,test_X,train_y,test_y =train_test_split(X,y,test_size=0.33,shuffle = True, random_state=45)\n",
    "pprint('--Data splitted done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(grid_scores, n_top=3):\n",
    "    \"\"\"Report top n_top parameters settings, default n_top=3.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    grid_scores -- output from grid or random search\n",
    "    n_top -- how many to report, of top models\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    top_params -- [dict] top parameter settings found in\n",
    "                  search\n",
    "    \"\"\"\n",
    "    top_scores = sorted(grid_scores,\n",
    "                        key=itemgetter(1),\n",
    "                        reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print((\"Mean validation score: \"\n",
    "               \"{0:.3f} (std: {1:.3f})\").format(\n",
    "               score.mean_validation_score,\n",
    "               np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")\n",
    "\n",
    "    return top_scores[0].parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_randomsearch(X, y, clf, para_dist, cv=5,\n",
    "                     n_iter_search=100):\n",
    "    \"\"\"Run a random search for best Decision Tree parameters.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    X -- features\n",
    "    y -- targets (classes)\n",
    "    cf -- scikit-learn Decision Tree\n",
    "    param_dist -- [dict] list, distributions of parameters\n",
    "                  to sample\n",
    "    cv -- fold of cross-validation, default 5\n",
    "    n_iter_search -- number of random parameter sets to try,\n",
    "                     default 20.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    top_params -- [dict] from report()\n",
    "    \"\"\"\n",
    "    random_search = RandomizedSearchCV(clf,\n",
    "                        param_distributions=param_dist,\n",
    "                        n_iter=n_iter_search, n_jobs= -1)\n",
    "\n",
    "    start = time()\n",
    "    random_search.fit(X, y)\n",
    "    print((\"\\nRandomizedSearchCV took {:.2f} seconds \"\n",
    "           \"for {:d} candidates parameter \"\n",
    "           \"settings.\").format((time() - start),\n",
    "                               n_iter_search))\n",
    "\n",
    "    top_params = report(random_search.grid_scores_, 3)\n",
    "    return  top_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold #for K-fold cross validation\n",
    "from sklearn.model_selection import cross_val_score, cross_validate #score evaluation\n",
    "from sklearn.model_selection import cross_val_predict #prediction\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score, accuracy_score\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "scoring = {'precision': make_scorer(precision_score),\n",
    "           'recall': make_scorer(recall_score),\n",
    "           'F-score': make_scorer( f1_score),\n",
    "           'accuracy': make_scorer(accuracy_score)}\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=1) # k=10, split the data into 10 equal parts\n",
    "\n",
    "classifiers=['gradientBoosting_Tuned']\n",
    "#models=[gradientBoosting_DT]\n",
    "gbm_tuned_1 = GradientBoostingClassifier(learning_rate=0.005, n_estimators=1600,max_depth=5, min_samples_split=600, min_samples_leaf=30, subsample=0.85, random_state=10,max_features = 3)\n",
    "models=[gbm_tuned_1]\n",
    "\n",
    "\n",
    "fit_time = []\n",
    "score_time = []\n",
    "\n",
    "test_accuracy = []\n",
    "test_accuracy_total = []\n",
    "\n",
    "test_accuracy_std = []\n",
    "train_accuracy = []\n",
    "train_accuracy_total = []\n",
    "train_accuracy_std = []\n",
    "\n",
    "\n",
    "test_F_score = []\n",
    "test_F_score_total = []\n",
    "\n",
    "\n",
    "test_F_score_std = []\n",
    "train_F_score = []\n",
    "train_F_score_total = []\n",
    "\n",
    "train_F_score_std = []\n",
    "\n",
    "\n",
    "test_precision = []\n",
    "test_precision_std = []\n",
    "train_precision = []\n",
    "train_precision_std = []\n",
    "\n",
    "\n",
    "test_recall = []\n",
    "test_recall_std = []\n",
    "train_recall = []\n",
    "train_recall_std = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in models:\n",
    "    model = i\n",
    "    scores = cross_validate(model,X,y, cv = kfold, scoring = scoring, return_train_score=True)\n",
    "    fit_time.append(scores['fit_time'].mean())\n",
    "    score_time.append(scores['score_time'].mean())\n",
    "    \n",
    "    test_accuracy.append(scores['test_accuracy'].mean())\n",
    "    test_accuracy_total.append(scores['test_accuracy'])\n",
    "    \n",
    "    test_accuracy_std.append(scores['test_accuracy'].std())\n",
    "    train_accuracy.append(scores['train_accuracy'].mean())\n",
    "    train_accuracy_total.append(scores['train_accuracy'])\n",
    "                          \n",
    "    train_accuracy_std.append(scores['train_accuracy'].std())\n",
    "    \n",
    "    test_F_score.append(scores['test_F-score'].mean())\n",
    "    test_F_score_total.append(scores['test_F-score'])\n",
    "    \n",
    "    test_F_score_std.append(scores['test_F-score'].std())\n",
    "    train_F_score.append(scores['train_F-score'].mean())\n",
    "    train_F_score_total.append(scores['train_F-score'])\n",
    "                         \n",
    "                         \n",
    "    train_F_score_std.append(scores['train_F-score'].std())\n",
    "    \n",
    "    test_precision.append(scores['test_precision'].mean())\n",
    "    test_precision_std.append(scores['test_precision'].std())\n",
    "    train_precision.append(scores['train_precision'].mean())\n",
    "    train_precision_std.append(scores['train_precision'].std())\n",
    "    \n",
    "    test_recall.append(scores['test_recall'].mean())\n",
    "    test_recall_std.append(scores['test_recall'].std())\n",
    "    train_recall.append(scores['train_recall'].mean())\n",
    "    train_recall_std.append(scores['train_recall'].std())\n",
    "    \n",
    "\n",
    "    print('Model: ' + str(i))\n",
    "\n",
    "sorted(scores.keys())     \n",
    "dct_acc = {'Test_accuracy':test_accuracy,\n",
    "               'Test_accuracy_std':test_accuracy_std,\n",
    "               'Train_accuracy':train_accuracy,\n",
    "               'Train_accuracy_std':train_accuracy_std, }\n",
    "dct_Fscore = {'Test_F_score':test_F_score,\n",
    "               'Test_F_score_std':test_F_score_std,\n",
    "               'Train_F_score': train_F_score,\n",
    "               'Train_F_score_std': train_F_score_std}\n",
    "dct_precision = {'Test_precision': test_precision,\n",
    "               'Test_precision_std': test_precision_std,\n",
    "               'Train_precision': train_precision,\n",
    "               'Train_precision_std': train_precision_std}\n",
    "dct_recall = {'Test_Sensitivity': test_recall, \n",
    "               'Test_Sensitivity_std': test_recall_std,\n",
    "               'Train_Sensitivity': train_recall,\n",
    "               'Train_Sensitivity_std': train_recall_std}\n",
    "dct_time = {'Fit_time': fit_time, 'Scoring Time':score_time}\n",
    "\n",
    "metrics_acc=pd.DataFrame(dct_acc,index=classifiers)       \n",
    "metrics_Fsc = pd.DataFrame(dct_Fscore,index=classifiers)\n",
    "metrics_precision = pd.DataFrame(dct_precision,index=classifiers) \n",
    "metrics_recall = pd.DataFrame(dct_recall,index=classifiers)\n",
    "metrics_time = pd.DataFrame(dct_time,index=classifiers)\n",
    "           \n",
    "display(metrics_acc)\n",
    "display(metrics_Fsc)\n",
    "display(metrics_precision)\n",
    "display(metrics_recall)\n",
    "display(metrics_time)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.title('TEST accuracy')\n",
    "box_test_accuracy=pd.DataFrame(test_accuracy_total, index=[classifiers])\n",
    "box_test_accuracy.T.boxplot()\n",
    "plt.show()\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title('TRAIN accuracy')\n",
    "box_train_accuracy=pd.DataFrame(train_accuracy_total,index=[classifiers])\n",
    "box_train_accuracy.T.boxplot()\n",
    "plt.show()\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title('TEST F-SCORE')\n",
    "box_test_F_score=pd.DataFrame(test_F_score_total,index=[classifiers])\n",
    "box_test_F_score.T.boxplot()\n",
    "plt.show()\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title('TRAIN F-SCORE')\n",
    "box_train_F_score=pd.DataFrame(train_F_score_total,index=[classifiers])\n",
    "box_train_F_score.T.boxplot()\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(12,4))\n",
    "gbm_tuned_1 = GradientBoostingClassifier(learning_rate=0.01, n_estimators=800,max_depth=5, min_samples_split=600, min_samples_leaf=30, subsample=0.85, random_state=10,max_features = 3)\n",
    "y_pred = cross_val_predict(gbm_tuned_1,X,y,cv=10)\n",
    "sns.heatmap(confusion_matrix(y,y_pred),ax=ax[0],annot=True,fmt='2.0f')\n",
    "ax[0].set_title('Matrix for gradientBoost')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#gbm_tuned_1 = GradientBoostingClassifier(learning_rate=0.01, n_estimators=800,max_depth=5, min_samples_split=600, min_samples_leaf=30, subsample=0.85, random_state=10,max_features = 3)\n",
    "gbm_tuned_rs = GradientBoostingClassifier(learning_rate=0.05, n_estimators=80,max_depth=9, min_samples_split=200, min_samples_leaf=60, subsample=0.9, random_state=10,max_features = 11)\n",
    "models = [    \n",
    "    \n",
    "    {\n",
    "        'label' : 'GradientBoosting',\n",
    "        'model': gbm_tuned_rs, \n",
    "        'color': 'green',\n",
    "        'linestyle': '-.',\n",
    "        'markers': ''\n",
    "    },\n",
    "\n",
    "]\n",
    "\n",
    "# #############################################################################\n",
    "# Classification and ROC analysis\n",
    "random_state = np.random.RandomState(0)\n",
    "# Run classifier with cross-validation and plot ROC curves\n",
    "splits = 2\n",
    "cv = StratifiedKFold(n_splits=splits)\n",
    "\n",
    "\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "aucs_mean = []\n",
    "labels = []\n",
    "stds = []\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "for m in models:\n",
    "    i = 0\n",
    "    for i,(train_index, test_index) in enumerate(kfold.split(X, y)):\n",
    "        print('[Fold %d/%d]' % (i + 1, splits))\n",
    "        print(\"TRAIN:\", train_index, \"\\nTEST:\", test_index)\n",
    "        train_X = X.iloc[train_index]\n",
    "        train_y = y.iloc[train_index]\n",
    "        test_X = X.iloc[test_index]\n",
    "        test_y = y.iloc[test_index]\n",
    "        \n",
    "        \n",
    "        probas_ = m['model'].fit(train_X, train_y).predict_proba(test_X)\n",
    "        # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = roc_curve(test_y, probas_[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        print('this is fpr: ' + str(fpr) + '\\n')\n",
    "        print('this is tpr: ' + str(tpr) + '\\n')\n",
    "        print('this is AUC: ' + str(roc_auc) + '\\n')\n",
    "        \n",
    "        aucs.append(roc_auc)\n",
    "        #plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
    "        #         label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "        i += 1\n",
    "    #plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "    #         label='Luck', alpha=.8)\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "   \n",
    "    std_auc = np.std(aucs)\n",
    "    \n",
    "\n",
    "    plt.plot(mean_fpr, mean_tpr, color= m['color'], linestyle = m['linestyle'], marker= m['markers'],\n",
    "             label=r'[%s]  AUC = %0.5f $\\pm$ %0.4f ' % (m['label'] ,mean_auc, std_auc),\n",
    "             lw=2, alpha=.8)\n",
    "    \n",
    "   \n",
    "    aucs_mean.append(mean_auc)\n",
    "    stds.append(std_auc)\n",
    "    labels.append(m['label']) \n",
    "\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    #plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                    # label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "AUCs=pd.DataFrame({'AUC Mean':aucs_mean, 'std':stds },index = labels)       \n",
    "AUCs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "from IPython.display import display, HTML\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "aucs = []\n",
    "train_cv_scores = []\n",
    "test_cv_scores = []\n",
    "auc_all_train = []\n",
    "auc_all_test = []\n",
    "\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "aucs_mean = []\n",
    "labels = []\n",
    "stds = []\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold,StratifiedKFold #for K-fold cross validation\n",
    " # k=10, split the data into 10 equal parts\n",
    "\n",
    "\n",
    "def modelfit(alg, X, y, performCV=True, printFeatureImportance=True, splits = 10):\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=splits)\n",
    "     \n",
    "    for i,(train_index, test_index) in enumerate(cv.split(X, y)):\n",
    "        print('[Fold %d/%d]' % (i + 1, splits))\n",
    "        #print(\"TRAIN:\", train_index, \"\\nTEST:\", test_index)\n",
    "        train_X = X.iloc[train_index]\n",
    "        train_y = y.iloc[train_index]\n",
    "        test_X = X.iloc[test_index]\n",
    "        test_y = y.iloc[test_index]\n",
    "        \n",
    "        \n",
    "    \n",
    "        test_probas_ = alg.fit(train_X, train_y).predict_proba(test_X)\n",
    "        test_pred = alg.fit(train_X, train_y).predict(test_X)\n",
    "        \n",
    "        train_probas_ = alg.fit(train_X, train_y).predict_proba(train_X)\n",
    "        train_pred = alg.fit(train_X, train_y).predict(train_X)\n",
    "        \n",
    "        \n",
    "        # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = roc_curve(test_y, test_probas_[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        #print('this is fpr: ' + str(fpr) + '\\n')\n",
    "        #print('this is tpr: ' + str(tpr) + '\\n')\n",
    "        print('this is AUC: ' + str(roc_auc) + '\\n')\n",
    "        \n",
    "        aucs.append(roc_auc)\n",
    "    \n",
    "        #Fit the algorithm on the data\n",
    "        alg.fit(X, y)\n",
    "\n",
    "        #Predict training set:\n",
    "        dtrain_predictions = train_pred\n",
    "        dtrain_predprob = train_probas_[:,1]\n",
    "        #Predict test set:\n",
    "        dtest_predictions = test_pred\n",
    "        dtest_predprob = test_probas_[:,1]\n",
    "\n",
    "        cv_score_train = metrics.accuracy_score(train_y, dtrain_predictions)\n",
    "       \n",
    "        cv_score_test = metrics.accuracy_score(test_y, dtest_predictions)\n",
    "        auc_train = metrics.roc_auc_score(train_y, dtrain_predprob)\n",
    "        auc_test = metrics.roc_auc_score(test_y, dtest_predprob)\n",
    "        \n",
    "        train_cv_scores.append(cv_score_train)\n",
    "        test_cv_scores.append(cv_score_test)\n",
    "        auc_all_train.append(auc_train)\n",
    "        auc_all_test.append(auc_test)\n",
    "        \n",
    "   \n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = np.mean(aucs)\n",
    "   \n",
    "    std_auc = np.std(aucs)\n",
    "    \n",
    "\n",
    "    plt.plot(mean_fpr, mean_tpr, color= m['color'], linestyle = m['linestyle'], marker= m['markers'],\n",
    "             label=r'[%s]  AUC = %0.5f $\\pm$ %0.4f ' % (m['label'] ,mean_auc, std_auc),\n",
    "             lw=2, alpha=.8)\n",
    "    \n",
    "    \n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "   \n",
    "    \n",
    "    #if performCV:\n",
    "     #   print (\"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
    "\n",
    "    #Print Feature Importance:\n",
    "    if printFeatureImportance:\n",
    "        feat_imp = pd.Series(alg.feature_importances_, X.columns).sort_values(ascending=False)\n",
    "        feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "        plt.ylabel('Feature Importance Score')\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    aucs_mean.append(mean_auc)\n",
    "    stds.append(std_auc)\n",
    "    labels.append(m['label']) \n",
    "    \n",
    "\n",
    "    \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy train (mean 10-cv): %0.5f $\\pm$ %0.4f\" %  (np.mean(train_cv_scores, axis=0), np.std(train_cv_scores, axis=0)))\n",
    "    print(\"Accuracy test (mean 10-cv): %0.5f $\\pm$ %0.4f\" % (np.mean(test_cv_scores, axis=0), np.std(test_cv_scores, axis=0)))\n",
    "    print(\"AUC Score (Train) (mean 10-cv): %0.5f $\\pm$ %0.4f\" % (np.mean(auc_all_train, axis=0), np.std(auc_all_train, axis=0)))\n",
    "    print(\"AUC Score (Test) (mean 10-cv): %0.5f $\\pm$ %0.4f\" %(np.mean(auc_all_test, axis=0), np.std(auc_all_test, axis=0)))\n",
    "    \n",
    "    AUCs=pd.DataFrame({'AUC Mean':aucs_mean, 'std':stds },index = labels)       \n",
    "    display(AUCs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = X.columns\n",
    "gbm0 = GradientBoostingClassifier(random_state=10)\n",
    "modelfit(gbm0, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = X.columns\n",
    "param_test1 = {'n_estimators':np.arange(20,81,10)}\n",
    "gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, min_samples_split=500,min_samples_leaf=50,max_depth=8,max_features='sqrt',subsample=0.8,random_state=10),param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_test2 = {'max_depth':np.arange(5,16,2), 'min_samples_split':np.arange(200,1001,200)}\n",
    "gsearch2 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=80, max_features='sqrt', subsample=0.8, random_state=10), \n",
    "param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=10)\n",
    "gsearch2.fit(X,y)\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test3 = {'min_samples_split':np.arange(600,700,5), 'min_samples_leaf':np.arange(30,71,10)}\n",
    "gsearch3 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=80,max_depth=5,max_features='sqrt', subsample=0.8, random_state=10), \n",
    "param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=10)\n",
    "gsearch3.fit(X,y)\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfit(gsearch3.best_estimator_, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test4 = {'max_features':np.arange(1,13,2)}\n",
    "gsearch4 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=80,max_depth=5, min_samples_split=600, min_samples_leaf=30, subsample=0.8, random_state=10),\n",
    "param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=10)\n",
    "gsearch4.fit(X,y)\n",
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test5 = {'subsample':[0.6,0.7,0.75,0.8,0.85,0.9]}\n",
    "gsearch5 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=80,max_depth=5, min_samples_split=600, min_samples_leaf=30, subsample=0.8, random_state=10,max_features = 3),\n",
    "param_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=10)\n",
    "gsearch5.fit(X,y)\n",
    "gsearch5.grid_scores_, gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_tuned_1 = GradientBoostingClassifier(learning_rate=0.05, n_estimators=160,max_depth=5, min_samples_split=600, min_samples_leaf=30, subsample=0.85, random_state=10,max_features = 3)\n",
    "\n",
    "\n",
    "\n",
    "modelfit(gbm_tuned_1, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_tuned_1 = GradientBoostingClassifier(learning_rate=0.01, n_estimators=800,max_depth=5, min_samples_split=600, min_samples_leaf=30, subsample=0.85, random_state=10,max_features = 3)\n",
    "\n",
    "\n",
    "\n",
    "modelfit(gbm_tuned_1, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_tuned_1 = GradientBoostingClassifier(learning_rate=0.01, n_estimators=700,max_depth=5, min_samples_split=600, min_samples_leaf=30, subsample=0.85, random_state=10,max_features = 3)\n",
    "modelfit(gbm_tuned_1, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gbm_tuned_1 = GradientBoostingClassifier(learning_rate=0.005, n_estimators=1600,max_depth=5, min_samples_split=600, min_samples_leaf=30, subsample=0.85, random_state=10,max_features = 3)\n",
    "gbm_tuned_1 = GradientBoostingClassifier(learning_rate=0.05, n_estimators=80,max_depth=9, min_samples_split=200, min_samples_leaf=60, subsample=0.9, random_state=10,max_features = 11)\n",
    "modelfit(gbm_tuned_rs, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'----Random Search XGBoost\\n'\n",
      "\n",
      "RandomizedSearchCV took 160.79 seconds for 24 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.782 (std: 0.011)\n",
      "Parameters: {'n_estimators': 80, 'learning_rate': 0.1, 'subsample': 0.6, 'reg_alpha': 0.0001, 'colsample_bytree': 0.7, 'min_child_weight': 11, 'max_depth': 7, 'gamma': 0.1}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.780 (std: 0.015)\n",
      "Parameters: {'n_estimators': 50, 'learning_rate': 0.1, 'subsample': 0.75, 'reg_alpha': 1, 'colsample_bytree': 0.9, 'min_child_weight': 7, 'max_depth': 3, 'gamma': 0.2}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.780 (std: 0.015)\n",
      "Parameters: {'n_estimators': 70, 'learning_rate': 0.05, 'subsample': 0.7, 'reg_alpha': 0.01, 'colsample_bytree': 0.6, 'min_child_weight': 9, 'max_depth': 9, 'gamma': 0.1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from sklearn.model_selection import KFold,StratifiedKFold #for K-fold cross validation\n",
    "import xgboost as xg\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=22) # k=10, split the data into 10 equal parts\n",
    "#gbm_tuned_1 = GradientBoostingClassifier(learning_rate=0.05, n_estimators=80,max_depth=9, min_samples_split=200, min_samples_leaf=60, subsample=0.9, random_state=10,max_features = 11)\n",
    "XGB_clf = xg.XGBClassifier(learning_rate =0.1, gamma=0, objective= 'binary:logistic',nthread=4, scale_pos_weight=1, seed=27, n_estimators = 50,max_depth = 9,)\n",
    "\n",
    "param_dist2 = {'n_estimators':np.arange(20,201,10)}\n",
    "param_dist3 = {'max_depth':np.arange(9,21,2),\n",
    "              'min_child_weight':np.arange(11,21,2)}\n",
    "\n",
    "\n",
    "\n",
    "param_dist = {'max_depth':np.arange(3,10,2),\n",
    "              'min_child_weight':np.arange(1,12,2),\n",
    "              'gamma':[i/10.0 for i in range(0,5)],\n",
    "              'subsample':[0.6,0.7,0.75,0.8,0.85,0.9],\n",
    "              'colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "              'reg_alpha':[1e-5, 1e-4, 1e-3, 1e-2, 1e-1,1, 1e1,1e2,1e3],\n",
    "              'learning_rate': [0.1,0.05,0.001],\n",
    "              'n_estimators':np.arange(20,81,10)}\n",
    "pprint('----Random Search XGBoost\\n')\n",
    "\n",
    "\n",
    "\n",
    "DT_rs = run_randomsearch(X, y, XGB_clf, param_dist3, cv=kfold,\n",
    "                         n_iter_search=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'----Random Search XGBoost\\n'\n",
      "\n",
      "RandomizedSearchCV took 248.09 seconds for 24 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.785 (std: 0.016)\n",
      "Parameters: {'min_child_weight': 13, 'max_depth': 15}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.785 (std: 0.016)\n",
      "Parameters: {'min_child_weight': 13, 'max_depth': 11}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.785 (std: 0.016)\n",
      "Parameters: {'min_child_weight': 13, 'max_depth': 9}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from sklearn.model_selection import KFold,StratifiedKFold #for K-fold cross validation\n",
    "import xgboost as xg\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=22) # k=10, split the data into 10 equal parts\n",
    "XGB_clf = xg.XGBClassifier(learning_rate =0.1, gamma=0, objective= 'binary:logistic',nthread=4, scale_pos_weight=1, seed=27, n_estimators = 50)\n",
    "param_dist = {'max_depth':np.arange(9,21,2),\n",
    "              'min_child_weight':np.arange(11,21,2)}\n",
    "pprint('----Random Search XGBoost\\n')\n",
    "\n",
    "XGB_rs = run_randomsearch(X, y, XGB_clf, param_dist, cv=kfold,\n",
    "                         n_iter_search=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from sklearn.model_selection import KFold,StratifiedKFold #for K-fold cross validation\n",
    "import xgboost as xg\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=22) # k=10, split the data into 10 equal parts\n",
    "XGB_clf = xg.XGBClassifier(learning_rate =0.1, gamma=0, objective= 'binary:logistic',nthread=4, scale_pos_weight=1, seed=27, n_estimators = 50, max_depth = 15,min_child_weight = 13)\n",
    "\n",
    "param_dist = {'gamma':[i/10.0 for i in range(0,5)]}\n",
    "pprint('----Random Search XGBoost\\n')\n",
    "\n",
    "XGB_rs = run_randomsearch(X, y, XGB_clf, param_dist, cv=kfold,\n",
    "                         n_iter_search=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
